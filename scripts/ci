#!/usr/bin/env python3

# Setting up sbuild requires the following commands:
#     sudo apt install sbuild
#     sudo sbuild-adduser "$USER"
#     newgrp sbuild
#     sudo sbuild-createchroot --include=eatmydata,ccache,gnupg --components=main,restricted,universe,multiverse artful /srv/chroot/artful-amd64-sbuild http://archive.ubuntu.com/ubuntu
#     sudo sbuild-createchroot --include=eatmydata,ccache,gnupg --components=main,restricted,universe,multiverse bionic /srv/chroot/bionic-amd64-sbuild http://archive.ubuntu.com/ubuntu

import argparse
from collections import namedtuple
from debian.changelog import Changelog, Version
from debian.deb822 import Dsc, Deb822
import os
from os import path
import shutil
from subprocess import check_call, check_output
import sys
import tempfile

from lib import foreach_repo, github_post

Series = namedtuple('Series', 'codename version')

parser = argparse.ArgumentParser(description="Package and deploy all Pop!_OS repositories")
parser.add_argument("repos", nargs="*", default=[])
args = parser.parse_args(sys.argv[1:])

POP_DIR = path.dirname(path.dirname(path.abspath(__file__)))
BUILD_DIR = path.join(POP_DIR, '_build')
GIT_DIR = path.join(BUILD_DIR, 'git')
SOURCE_DIR = path.join(BUILD_DIR, 'source')
BINARY_DIR = path.join(BUILD_DIR, 'binary')
REPO_DIR = path.join(BUILD_DIR, 'repos')

build_series = {
    'artful': '17.10',
    'bionic': '18.04',
}


def iprint(level, value):
    indent = ' ' * (level * 4)
    print('>>> ' + indent + str(value))


def git_ids_and_branches(cwd):
    """
    Returns a `dict` mapping each commit ID to a list of branches.

    `git ls-remote` will return something like::

        f73e8fc2c5bb5756032c35b6be1fcd84106413b1	refs/heads/overhaul
        ffb788cccfe0cd7feedcfe8f0b8e9154097a46ca	refs/heads/master
        f73e8fc2c5bb5756032c35b6be1fcd84106413b1	refs/heads/test_bionic

    For which this function would return::

        {
            'f73e8fc2c5bb5756032c35b6be1fcd84106413b1': ['overhaul', 'test_bionic'],
            'ffb788cccfe0cd7feedcfe8f0b8e9154097a46ca':	['master'],
        }
    """
    check_call(['git', 'fetch', 'origin'], cwd=cwd)
    o = check_output(['git', 'ls-remote', '--heads', 'origin'], cwd=cwd)
    prefix = 'refs/heads/'
    result = {}
    for line in o.decode().splitlines():
        (_id, rawbranch) = line.split('\t')
        assert rawbranch.startswith(prefix)
        branch = rawbranch[len(prefix):]
        if _id not in result:
            result[_id] = []
        result[_id].append(branch)
    return result


def git_clean(cwd):
    check_call(['git', 'clean', '-xfd'], cwd=cwd)


def git_checkout_id(cwd, _id):
    check_call(['git', 'checkout', '--force', '--detach', _id], cwd=cwd)
    check_call(['git', 'submodule', 'sync', '--recursive'], cwd=cwd)
    check_call(['git', 'submodule', 'update', '--init', '--recursive'], cwd=cwd)
    git_clean(cwd)


def git_timestamp_id(cwd, _id):
    o = check_output(["git", "log", "-1", "--pretty=format:%ct", _id], cwd=cwd)
    return o.decode().strip()


def git_datetime_id(cwd, _id):
    o = check_output(["git", "log", "-1", "--pretty=format:%cD", _id], cwd=cwd)
    return o.decode().strip()


def git_archive_id(cwd, _id, archive):
    return check_output(["git", "archive", "--format", "tar", "-o", archive, _id], cwd=cwd)


def parse_branch(branch):
    parts = branch.split('_')
    assert len(parts) <= 2
    pocket = parts[0]
    codename = (None if len(parts) < 2 else parts[1])
    return (pocket, codename)


def iter_series(branches):
    for b in branches:
        (pocket, codename) = parse_branch(b)
        if codename is None:
            for (codename, version) in build_series.items():
                yield (Series(codename, version), pocket)
        else:
            yield (Series(codename, build_series[codename]), pocket)


def expand_series(branches):
    result = {}
    for (series, pocket) in iter_series(branches):
        if series not in result:
            result[series] = set()
        result[series].add(pocket)
    return result

GitTar = namedtuple('GitTar', 'id timestamp datetime archive')

def git_tar(cwd, _id):
    timestamp = git_timestamp_id(cwd, _id)
    datetime = git_datetime_id(cwd, _id)
    archive = path.join(GIT_DIR, _id + ".tar")
    if path.exists(archive):
        print("Git already built for {!r} id {!r}".format(cwd, _id))
    else:
        git_archive_id(cwd, _id, archive)
    return GitTar(_id, timestamp, datetime, archive)


def github_status(name, _id, context, state):
    target_url = os.environ.get("BUILD_URL")
    if target_url is None:
        print("Not setting github status for {!r} {!r}".format(name, _id))
        return
    else:
        print("Setting github status for {!r} {!r}".format(name, _id))

    url = "https://api.github.com/repos/pop-os/" + name + "/statuses/" + _id

    data = {
        "context": "pop-os/staging/" + context,
        "description": "Pop!_OS Staging " + context,
        "state": state,
        "target_url": target_url
    }

    print('URL:', url)

    print('Data:', data)

    response = github_post(url, data)

    print('Response:', response)

    return response


def dpkg_source(name, git, series):
    prefix = name + "_" + git.id + "_" + series.codename + "_"
    with tempfile.TemporaryDirectory(prefix=prefix) as tempdir:
        print(tempdir)

        check_call(['tar', 'xf', git.archive], cwd=tempdir)

        if not path.isdir(path.join(tempdir, 'debian')):
             print('no debian dir: {!r}'.format(tempdir))
             return None, None

        with open(path.join(tempdir, "debian", "control"), "r") as fp:
            control = Deb822(fp)

        o = check_output(["dpkg-parsechangelog", "--show-field", "Version"], cwd=tempdir)
        changelog_version = o.decode().strip()

        source_name = control.get("Source")
        version = '+'.join([changelog_version, git.timestamp, series.version, git.id[:7]])

        dsc_path = path.join(SOURCE_DIR, source_name + "_" + version + ".dsc")
        tar_path = path.join(SOURCE_DIR, source_name + "_" + version + ".tar.xz")

        build = not path.exists(dsc_path) or not path.exists(tar_path)

        if build:
            try:
                github_status(name, git.id, series.codename + "/source", "pending")

                changelog = Changelog()

                changelog.new_block(
                    package=source_name,
                    version=Version(version),
                    distributions=series.codename,
                    author='Pop Launchpad <pop.launchpad@system76.com>',
                    date=git.datetime
                )

                changelog.add_change('')
                changelog.add_change('  * Auto Build')
                changelog.add_change('')

                with open(path.join(tempdir, 'debian', 'changelog'), 'w') as fp:
                    changelog.write_to_open_file(fp)

                check_call([
                    "dh", "clean"
                ], cwd=tempdir)

                env = {"SOURCE_DATE_EPOCH": str(git.timestamp)}
                check_call([
                    'dpkg-source',
                    '--compression=xz',
                    '--build', tempdir
                ], cwd=SOURCE_DIR, env=env)

                github_status(name, git.id, series.codename + "/source", "success")
            except:
                github_status(name, git.id, series.codename + "/source", "failure")
                raise
        else:
            print("Source already built for {!r} on {!r}".format(source_name, series))

        return dsc_path, tar_path


def dpkg_binary(dsc_path, name, git, series):
    with open(dsc_path, "r") as fp:
        dsc = Dsc(fp)

    source_name = dsc.get("Source")
    binaries = dsc.get("Binary")
    version = dsc.get("Version")
    arch = dsc.get("Architecture")

    if arch != "all":
        print("Setting arch to amd64")
        arch = "amd64"

    build = False

    debs = []

    for binary in binaries.split(", "):
        deb_path = path.join(BINARY_DIR, binary + "_" + version + "_" + arch + ".deb")
        debs.append(deb_path)
        if not path.exists(deb_path):
            build = True

    if build:
        try:
            github_status(name, git.id, series.codename + "/binary", "pending")

            check_call([
                "sbuild",
                "--verbose",
                "--arch-all",
                "--batch",
                "--run-autopkgtest",
                "--dist=" + series.codename,
                "--extra-repository=deb http://ppa.launchpad.net/system76/pop/ubuntu " + series.codename + " main",
                "--extra-repository-key=" + path.join(POP_DIR, "scripts", ".ppa.asc"),
                dsc_path
            ], cwd=BINARY_DIR)

            github_status(name, git.id, series.codename + "/binary", "success")
        except:
            github_status(name, git.id, series.codename + "/binary", "failure")
            raise
    else:
        print("Binaries already built for {!r} on {!r}".format(source_name, series))

    return debs


def build_packages(name):
    cwd = path.join(POP_DIR, name)

    print('')
    iprint(0, name + ": " + cwd)

    if not path.exists(cwd):
        print('did not find: {!r}'.format(cwd))
        return {}

    pocket_series = {}

    ids = git_ids_and_branches(cwd)
    for (_id, branches) in sorted(ids.items()):
        git = git_tar(cwd, _id)

        iprint(1, git.id + ": " + git.datetime)

        expanded = expand_series(branches)
        for (series, pockets) in sorted(expanded.items()):
            iprint(2, series)

            dsc_path, tar_path = dpkg_source(name, git, series)

            if dsc_path and tar_path:
                deb_paths = dpkg_binary(dsc_path, name, git, series)

                for pocket in sorted(pockets):
                    iprint(3, pocket)

                    if not pocket in pocket_series:
                        pocket_series[pocket] = []

                    if not series in pocket_series[pocket]:
                        pocket_series[pocket].append(series)

                    # Produce pool: http://ppa.launchpad.net/system76/pop/ubuntu/pool/
                    pool_dir = path.join(REPO_DIR, pocket, "pool", series.codename, name)
                    os.makedirs(pool_dir)

                    for deb_path in deb_paths:
                        iprint(4, path.basename(deb_path))

                        shutil.copy2(dsc_path, path.join(pool_dir, path.basename(dsc_path)))
                        shutil.copy2(tar_path, path.join(pool_dir, path.basename(tar_path)))
                        shutil.copy2(deb_path, path.join(pool_dir, path.basename(deb_path)))

    return pocket_series


def create_dists(email, pocket_series):
    for pocket in pocket_series:
        iprint(0, pocket)

        pocket_dir = path.join(REPO_DIR, pocket)

        for series in pocket_series[pocket]:
            iprint(1, series)

            dist_dir = path.join(pocket_dir, "dists", series.codename)
            os.makedirs(dist_dir)

            comp_dir = path.join(dist_dir, "main")
            os.mkdir(comp_dir)

            source_dir = path.join(comp_dir, "source")
            os.mkdir(source_dir)

            binary_dir = path.join(comp_dir, "binary-amd64")
            os.mkdir(binary_dir)

            # Generate source directory: http://ppa.launchpad.net/system76/pop/ubuntu/dists/artful/main/source/
            source = check_output([
                "apt-ftparchive", "-qq",
                "sources", path.join("pool", series.codename)
            ], cwd=pocket_dir).decode()

            with open(path.join(source_dir, "Sources"), "w") as f:
                f.write(source)

            check_call(["gzip", "--keep", path.join(source_dir, "Sources")])

            # Example source release file: http://ppa.launchpad.net/system76/pop/ubuntu/dists/artful/main/source/Release
            with open(path.join(source_dir, "Release"), "w") as f:
                f.write("Archive: " + series.codename + "\n")
                f.write("Version: " + series.version + "\n")
                f.write("Component: main\n")
                f.write("Origin: pop-os-staging-" + pocket + "\n")
                f.write("Label: Pop!_OS Staging " + pocket + "\n")
                f.write("Architecture: source\n")

            # Generate binary directory: http://ppa.launchpad.net/system76/pop/ubuntu/dists/artful/main/binary-amd64/
            packages = check_output([
                "apt-ftparchive",
                "packages", path.join("pool", series.codename)
            ], cwd=pocket_dir).decode()

            with open(path.join(binary_dir, "Packages"), "w") as f:
                f.write(packages)

            check_call(["gzip", "--keep", path.join(binary_dir, "Packages")])

            # Example binary release file: http://ppa.launchpad.net/system76/pop/ubuntu/dists/artful/main/binary-amd64/Release
            with open(path.join(binary_dir, "Release"), "w") as f:
                f.write("Archive: " + series.codename + "\n")
                f.write("Version: " + series.version + "\n")
                f.write("Component: main\n")
                f.write("Origin: pop-os-staging-" + pocket + "\n")
                f.write("Label: Pop!_OS Staging " + pocket + "\n")
                f.write("Architecture: amd64\n")

            # Example dists release file: http://ppa.launchpad.net/system76/pop/ubuntu/dists/artful/Release
            release = check_output([
                "apt-ftparchive",
        		"-o", "APT::FTPArchive::Release::Origin=pop-os-staging-" + pocket,
        		"-o", "APT::FTPArchive::Release::Label=Pop!_OS Staging " + pocket,
        		"-o", "APT::FTPArchive::Release::Suite=" + series.codename,
        		"-o", "APT::FTPArchive::Release::Version=" + series.version,
        		"-o", "APT::FTPArchive::Release::Codename=" + series.codename,
        		"-o", "APT::FTPArchive::Release::Architectures=amd64",
        		"-o", "APT::FTPArchive::Release::Components=main",
        		"-o", "APT::FTPArchive::Release::Description=Pop!_OS Staging " + series.codename + " " + series.version + " " + pocket,
                "release", "."
            ], cwd=dist_dir).decode()

            with open(path.join(dist_dir, "Release"), "w") as f:
                f.write(release)

            check_call([
                "gpg", "--clearsign",
                "--local-user", email,
                "--batch", "--yes",
                "--digest-algo", "sha512",
                "-o", path.join(dist_dir, "InRelease"), path.join(dist_dir, "Release")
            ])

            check_call([
                "gpg", "-abs",
                "--local-user", email,
                "--batch", "--yes",
                "--digest-algo", "sha512",
                "-o", path.join(dist_dir, "Release.gpg"), path.join(dist_dir, "Release")
            ])

            check_call([
                "gpg", "--export", "--armor",
                "--local-user", email,
                "--batch", "--yes",
                "--digest-algo", "sha512",
                "-o", path.join(dist_dir, "Key.gpg")
            ])


def callback(repo):
    name =  repo['name']

    if name in (
        'code-of-conduct',
        'docs',
        'gnome-control-center',
        'gnome-desktop',
        'gnome-initial-setup',
        'iso',
    ):
        print('skipping {!r}'.format(name))
        return {}
    else:
        return build_packages(name)


def create_dir(d):
    if not path.isdir(d):
        os.mkdir(d)


def recreate_dir(d):
    if path.isdir(d):
        shutil.rmtree(d)
        os.mkdir(d)


def ci():
    email = os.environ.get("DEBEMAIL")
    if email is None:
        raise Exception("DEBEMAIL is not set")

    create_dir(BUILD_DIR)

    create_dir(GIT_DIR)
    create_dir(SOURCE_DIR)
    create_dir(BINARY_DIR)
    recreate_dir(REPO_DIR)

    all_pocket_series = {}
    for repo_name, pocket_series in foreach_repo(callback, args.repos).items():
        for pocket in pocket_series:
            for series in pocket_series[pocket]:
                if not pocket in all_pocket_series:
                    all_pocket_series[pocket] = []

                if not series in all_pocket_series[pocket]:
                    all_pocket_series[pocket].append(series)

    create_dists(email, all_pocket_series)


ci()
